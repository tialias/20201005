{"name": "testcase description", "status": "broken", "statusDetails": {"message": "httprunner.exceptions.ValidationFailure: assert status_code equal 200(int)\t==> fail\ncheck_item: status_code\ncheck_value: 0(int)\nassert_method: equal\nexpect_value: 200(int)", "trace": "self = <testcases.mul_field_test.TestCaseMulField object at 0x108dc3150>, param = None\n\n    def test_start(self, param: Dict = None) -> \"HttpRunner\":\n        \"\"\"main entrance, discovered by pytest\"\"\"\n        self.__init_tests__()\n        self.__project_meta = self.__project_meta or load_project_meta(\n            self.__config.path\n        )\n        self.__case_id = self.__case_id or str(uuid.uuid4())\n        self.__log_path = self.__log_path or os.path.join(\n            self.__project_meta.RootDir, \"logs\", f\"{self.__case_id}.run.log\"\n        )\n        log_handler = logger.add(self.__log_path, level=\"DEBUG\")\n    \n        # parse config name\n        config_variables = self.__config.variables\n        if param:\n            config_variables.update(param)\n        config_variables.update(self.__session_variables)\n        self.__config.name = parse_data(\n            self.__config.name, config_variables, self.__project_meta.functions\n        )\n    \n        if USE_ALLURE:\n            # update allure report meta\n            allure.dynamic.title(self.__config.name)\n            allure.dynamic.description(f\"TestCase ID: {self.__case_id}\")\n    \n        logger.info(\n            f\"Start to run testcase: {self.__config.name}, TestCase ID: {self.__case_id}\"\n        )\n    \n        try:\n            return self.run_testcase(\n>               TestCase(config=self.__config, teststeps=self.__teststeps)\n            )\n\n../../python_env/hrenv/lib/python3.7/site-packages/httprunner/runner.py:456: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n../../python_env/hrenv/lib/python3.7/site-packages/httprunner/runner.py:357: in run_testcase\n    extract_mapping = self.__run_step(step)\n../../python_env/hrenv/lib/python3.7/site-packages/httprunner/runner.py:295: in __run_step\n    step_data = self.__run_step_request(step)\n../../python_env/hrenv/lib/python3.7/site-packages/httprunner/runner.py:209: in __run_step_request\n    validators, variables_mapping, self.__project_meta.functions\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <httprunner.response.ResponseObject object at 0x108ea2ad0>, validators = [{'equal': ['status_code', 200, '']}]\nvariables_mapping = {'a_response': None, 'request': {'allow_redirects': True, 'cookies': {'Hm_lpvt_47cd03e974df6869353431fe4f4d6b2f': '160...': '1', ...}, 'data': None, 'json': None, ...}, 'response': <httprunner.response.ResponseObject object at 0x108ea2ad0>}\nfunctions_mapping = {'email_field_data': <function email_field_data at 0x108d5bb90>, 'gen_nodeId': <function gen_nodeId at 0x108d5b440>, '...on get_field_codetype at 0x108d5b830>, 'get_httprunner_version': <function get_httprunner_version at 0x108cd6d40>, ...}\n\n    def validate(\n        self,\n        validators: Validators,\n        variables_mapping: VariablesMapping = None,\n        functions_mapping: FunctionsMapping = None,\n    ) -> NoReturn:\n    \n        variables_mapping = variables_mapping or {}\n        functions_mapping = functions_mapping or {}\n    \n        self.validation_results = {}\n        if not validators:\n            return\n    \n        validate_pass = True\n        failures = []\n    \n        for v in validators:\n    \n            if \"validate_extractor\" not in self.validation_results:\n                self.validation_results[\"validate_extractor\"] = []\n    \n            u_validator = uniform_validator(v)\n    \n            # check item\n            check_item = u_validator[\"check\"]\n            if \"$\" in check_item:\n                # check_item is variable or function\n                check_item = parse_data(\n                    check_item, variables_mapping, functions_mapping\n                )\n                check_item = parse_string_value(check_item)\n    \n            if check_item and isinstance(check_item, Text):\n                check_value = self._search_jmespath(check_item)\n            else:\n                # variable or function evaluation result is \"\" or not text\n                check_value = check_item\n    \n            # comparator\n            assert_method = u_validator[\"assert\"]\n            assert_func = get_mapping_function(assert_method, functions_mapping)\n    \n            # expect item\n            expect_item = u_validator[\"expect\"]\n            # parse expected value with config/teststep/extracted variables\n            expect_value = parse_data(expect_item, variables_mapping, functions_mapping)\n    \n            # message\n            message = u_validator[\"message\"]\n            # parse message with config/teststep/extracted variables\n            message = parse_data(message, variables_mapping, functions_mapping)\n    \n            validate_msg = f\"assert {check_item} {assert_method} {expect_value}({type(expect_value).__name__})\"\n    \n            validator_dict = {\n                \"comparator\": assert_method,\n                \"check\": check_item,\n                \"check_value\": check_value,\n                \"expect\": expect_item,\n                \"expect_value\": expect_value,\n                \"message\": message,\n            }\n    \n            try:\n                assert_func(check_value, expect_value, message)\n                validate_msg += \"\\t==> pass\"\n                logger.info(validate_msg)\n                validator_dict[\"check_result\"] = \"pass\"\n            except AssertionError as ex:\n                validate_pass = False\n                validator_dict[\"check_result\"] = \"fail\"\n                validate_msg += \"\\t==> fail\"\n                validate_msg += (\n                    f\"\\n\"\n                    f\"check_item: {check_item}\\n\"\n                    f\"check_value: {check_value}({type(check_value).__name__})\\n\"\n                    f\"assert_method: {assert_method}\\n\"\n                    f\"expect_value: {expect_value}({type(expect_value).__name__})\"\n                )\n                message = str(ex)\n                if message:\n                    validate_msg += f\"\\nmessage: {message}\"\n    \n                logger.error(validate_msg)\n                failures.append(validate_msg)\n    \n            self.validation_results[\"validate_extractor\"].append(validator_dict)\n    \n        if not validate_pass:\n            failures_string = \"\\n\".join([failure for failure in failures])\n>           raise ValidationFailure(failures_string)\nE           httprunner.exceptions.ValidationFailure: assert status_code equal 200(int)\t==> fail\nE           check_item: status_code\nE           check_value: 0(int)\nE           assert_method: equal\nE           expect_value: 200(int)\n\n../../python_env/hrenv/lib/python3.7/site-packages/httprunner/response.py:270: ValidationFailure"}, "description": "TestCase ID: c19d4c49-cdf1-4791-a240-2c5b712943fb", "steps": [{"name": "step: /f/jDRmyn", "status": "broken", "statusDetails": {"message": "httprunner.exceptions.ValidationFailure: assert status_code equal 200(int)\t==> fail\ncheck_item: status_code\ncheck_value: 0(int)\nassert_method: equal\nexpect_value: 200(int)\n", "trace": "  File \"/Users/tianliangliang/python_env/hrenv/lib/python3.7/site-packages/httprunner/runner.py\", line 357, in run_testcase\n    extract_mapping = self.__run_step(step)\n  File \"/Users/tianliangliang/python_env/hrenv/lib/python3.7/site-packages/httprunner/runner.py\", line 295, in __run_step\n    step_data = self.__run_step_request(step)\n  File \"/Users/tianliangliang/python_env/hrenv/lib/python3.7/site-packages/httprunner/runner.py\", line 209, in __run_step_request\n    validators, variables_mapping, self.__project_meta.functions\n  File \"/Users/tianliangliang/python_env/hrenv/lib/python3.7/site-packages/httprunner/response.py\", line 270, in validate\n    raise ValidationFailure(failures_string)\n"}, "start": 1606299144639, "stop": 1606299144652}], "attachments": [{"name": "stderr", "source": "049d30fb-83ec-4335-9202-a821007a0609-attachment.txt", "type": "text/plain"}], "start": 1606299144634, "stop": 1606299144654, "uuid": "3f8572f0-db0a-4a4c-b3fd-94eb296e3e4d", "historyId": "cc29d9b542993052ab93150b7056d363", "testCaseId": "816707ed2a4c1fdc793fc1ae09fe203a", "fullName": "testcases.mul_field_test.TestCaseMulField#test_start", "labels": [{"name": "parentSuite", "value": "testcases"}, {"name": "suite", "value": "mul_field_test"}, {"name": "subSuite", "value": "TestCaseMulField"}, {"name": "host", "value": "tianliangdeMBP2.lan"}, {"name": "thread", "value": "61906-MainThread"}, {"name": "framework", "value": "pytest"}, {"name": "language", "value": "cpython3"}, {"name": "package", "value": "testcases.mul_field_test"}]}